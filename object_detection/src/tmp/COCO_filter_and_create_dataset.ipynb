{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision\n",
        "!pip install roboflow\n",
        "!pip install pybboxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bCVWyaj9th9",
        "outputId": "5ded03b2-ff8d-484f-ee26-0559990b5ee2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.39)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Collecting pybboxes\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pybboxes) (1.26.4)\n",
            "Downloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pybboxes\n",
            "Successfully installed pybboxes-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import pybboxes as pbx\n",
        "import yaml\n",
        "import shutil\n",
        "import random\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "IdyUO2oBBuqE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8wbPHb6qzgm",
        "outputId": "95ebbc3e-884f-4772-ac44-2cc153d678a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-14 11:44:50--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.59.33, 3.5.29.126, 3.5.27.62, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.59.33|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip’\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  17.7MB/s    in 46s     \n",
            "\n",
            "2024-08-14 11:45:37 (17.0 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /data/coco/\n",
        "\n",
        "# Download the annotation ZIP and extract it, then remove the ZIP file\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q annotations_trainval2017.zip -d /data/coco/\n",
        "!rm annotations_trainval2017.zip\n",
        "\n",
        "# Download the train2017 ZIP, extract it, and remove the ZIP file\n",
        "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
        "# !unzip -q train2017.zip -d /data/coco/\n",
        "# !rm train2017.zip\n",
        "\n",
        "# Download the val2017 ZIP, extract it, and remove the ZIP file\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip -q val2017.zip -d /data/coco/\n",
        "!rm val2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# git for cleaning coco dataset\n",
        "!git clone https://github.com/immersive-limit/coco-manager.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlO5UgMnriMi",
        "outputId": "e929a01a-bda0-477d-e197-b55ae3d4ac96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coco-manager'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 2), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (8/8), done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/coco-manager/filter.py --input_json /data/coco/annotations/instances_val2017.json --output_json /data/coco/annotations/filtered_val.json --categories person dog cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXYNeVjriPM",
        "outputId": "22289294-0662-4ee3-b804-62a2184277f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading json file...\n",
            "Processing input json...\n",
            "Filtering...\n",
            "Saving new json file...\n",
            "Filtered json saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/data/coco/annotations/filtered_val.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "categories = data['categories']\n",
        "category_id_to_name = {category['id']: category['name'] for category in categories}\n",
        "\n",
        "for category_id, category_name in category_id_to_name.items():\n",
        "    print(f\"ID: {category_id}, Name: {category_name}\")\n",
        "\n",
        "\n",
        "# Print a few sample annotations\n",
        "# for i, annotation in enumerate(data['annotations']):\n",
        "#     print(f\"Annotation {i+1}:\")\n",
        "#     print(json.dumps(annotation, indent=4))\n",
        "#     print()\n",
        "#     if i == 1:\n",
        "#         break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No8uAcyrriRm",
        "outputId": "603e44ff-a73b-433c-b249-e33ede1b6709"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 1, Name: person\n",
            "ID: 2, Name: cat\n",
            "ID: 3, Name: dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/data/coco/annotations/instances_val2017.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "categories = data['categories']\n",
        "category_id_to_name = {category['id']: category['name'] for category in categories}\n",
        "\n",
        "for category_id, category_name in category_id_to_name.items():\n",
        "    print(f\"ID: {category_id}, Name: {category_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHFfUKlL6Vtq",
        "outputId": "4edc3ba0-e06e-44c9-e9af-32f8273b98d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 1, Name: person\n",
            "ID: 2, Name: bicycle\n",
            "ID: 3, Name: car\n",
            "ID: 4, Name: motorcycle\n",
            "ID: 5, Name: airplane\n",
            "ID: 6, Name: bus\n",
            "ID: 7, Name: train\n",
            "ID: 8, Name: truck\n",
            "ID: 9, Name: boat\n",
            "ID: 10, Name: traffic light\n",
            "ID: 11, Name: fire hydrant\n",
            "ID: 13, Name: stop sign\n",
            "ID: 14, Name: parking meter\n",
            "ID: 15, Name: bench\n",
            "ID: 16, Name: bird\n",
            "ID: 17, Name: cat\n",
            "ID: 18, Name: dog\n",
            "ID: 19, Name: horse\n",
            "ID: 20, Name: sheep\n",
            "ID: 21, Name: cow\n",
            "ID: 22, Name: elephant\n",
            "ID: 23, Name: bear\n",
            "ID: 24, Name: zebra\n",
            "ID: 25, Name: giraffe\n",
            "ID: 27, Name: backpack\n",
            "ID: 28, Name: umbrella\n",
            "ID: 31, Name: handbag\n",
            "ID: 32, Name: tie\n",
            "ID: 33, Name: suitcase\n",
            "ID: 34, Name: frisbee\n",
            "ID: 35, Name: skis\n",
            "ID: 36, Name: snowboard\n",
            "ID: 37, Name: sports ball\n",
            "ID: 38, Name: kite\n",
            "ID: 39, Name: baseball bat\n",
            "ID: 40, Name: baseball glove\n",
            "ID: 41, Name: skateboard\n",
            "ID: 42, Name: surfboard\n",
            "ID: 43, Name: tennis racket\n",
            "ID: 44, Name: bottle\n",
            "ID: 46, Name: wine glass\n",
            "ID: 47, Name: cup\n",
            "ID: 48, Name: fork\n",
            "ID: 49, Name: knife\n",
            "ID: 50, Name: spoon\n",
            "ID: 51, Name: bowl\n",
            "ID: 52, Name: banana\n",
            "ID: 53, Name: apple\n",
            "ID: 54, Name: sandwich\n",
            "ID: 55, Name: orange\n",
            "ID: 56, Name: broccoli\n",
            "ID: 57, Name: carrot\n",
            "ID: 58, Name: hot dog\n",
            "ID: 59, Name: pizza\n",
            "ID: 60, Name: donut\n",
            "ID: 61, Name: cake\n",
            "ID: 62, Name: chair\n",
            "ID: 63, Name: couch\n",
            "ID: 64, Name: potted plant\n",
            "ID: 65, Name: bed\n",
            "ID: 67, Name: dining table\n",
            "ID: 70, Name: toilet\n",
            "ID: 72, Name: tv\n",
            "ID: 73, Name: laptop\n",
            "ID: 74, Name: mouse\n",
            "ID: 75, Name: remote\n",
            "ID: 76, Name: keyboard\n",
            "ID: 77, Name: cell phone\n",
            "ID: 78, Name: microwave\n",
            "ID: 79, Name: oven\n",
            "ID: 80, Name: toaster\n",
            "ID: 81, Name: sink\n",
            "ID: 82, Name: refrigerator\n",
            "ID: 84, Name: book\n",
            "ID: 85, Name: clock\n",
            "ID: 86, Name: vase\n",
            "ID: 87, Name: scissors\n",
            "ID: 88, Name: teddy bear\n",
            "ID: 89, Name: hair drier\n",
            "ID: 90, Name: toothbrush\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/data/coco/annotations/filtered_val.json', 'r') as f:\n",
        "    filtered_data = json.load(f)\n",
        "\n",
        "filtered_image_ids = {annotation['image_id'] for annotation in filtered_data['annotations']}\n",
        "\n",
        "filtered_images = [image for image in filtered_data['images'] if image['id'] in filtered_image_ids]\n",
        "\n",
        "filtered_dataset = {\n",
        "    'images': filtered_images,\n",
        "    'annotations': filtered_data['annotations'],\n",
        "    'categories': filtered_data['categories']\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "Tq9qDW2v8oHK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unlisted_images(image_dir, filtered_dataset):\n",
        "    \"\"\"\n",
        "    Removes all images from the specified directory that are not listed in the filtered dataset (after class filtration).\n",
        "\n",
        "    Parameters:\n",
        "    - image_dir (str): The directory containing the images to be filtered.\n",
        "    - filtered_dataset (dict): Dictionary containing filtered 'images', 'annotations', and 'categories'.\n",
        "\n",
        "    Description:\n",
        "    This function scans the provided image directory and removes any image files that are not\n",
        "    present in the `filtered_dataset['images']` list.\n",
        "    \"\"\"\n",
        "\n",
        "    retained_images = {image_info['file_name'] for image_info in filtered_dataset['images']}\n",
        "\n",
        "    all_images = set(os.listdir(image_dir))\n",
        "\n",
        "    unlisted_images = all_images - retained_images\n",
        "\n",
        "    for image_filename in unlisted_images:\n",
        "        image_path = os.path.join(image_dir, image_filename)\n",
        "        os.remove(image_path)\n",
        "\n",
        "    print(f\"Cleanup complete. {len(unlisted_images)} unlisted images have been removed.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YvqZMeWFbC-D"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unlisted images\n",
        "remove_unlisted_images(\"/data/coco/val2017\", filtered_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPsBcfqhcD6U",
        "outputId": "7178b0f1-5ffc-4cc2-c770-ee8d2b230b03"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleanup complete. 2055 unlisted images have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset['categories']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VAKu_V8K8zlF",
        "outputId": "f88951e8-7c5f-43d4-cf13-794bb0db8522"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
              " {'supercategory': 'animal', 'id': 2, 'name': 'cat'},\n",
              " {'supercategory': 'animal', 'id': 3, 'name': 'dog'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_dataset['images'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6YYFvYvRyX_",
        "outputId": "93925dca-ab6d-4c03-949e-9251cd43f1c6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2945"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"API_key\")\n",
        "project = rf.workspace(\"atathamuscoinsdataset\").project(\"u.s.-coins-dataset-a.tatham\")\n",
        "dataset = project.version(5).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJHfLj5d94Ve",
        "outputId": "eb624efa-10ea-42a3-dfc2-55728fcfc8de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in U.S.-Coins-Dataset---A.Tatham-5 to yolov5pytorch:: 100%|██████████| 201549/201549 [00:15<00:00, 12940.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to U.S.-Coins-Dataset---A.Tatham-5 in yolov5pytorch:: 100%|██████████| 3306/3306 [00:01<00:00, 1666.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def coco_to_yolo(coco_annotation_path, images_dir, output_dir, yaml_output_path=None):\n",
        "    \"\"\"\n",
        "    Converts COCO format annotations to YOLO format and generates a YAML file describing the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - coco_annotation_path (str): Path to the COCO annotation JSON file.\n",
        "    - images_dir (str): Directory containing the images referenced in the COCO annotations.\n",
        "    - output_dir (str): Directory where YOLO format annotation files will be saved.\n",
        "    - yaml_output_path (str, optional): Path to save the generated YAML file. If None, it will save in the `output_dir`.\n",
        "\n",
        "    Description:\n",
        "    This function reads annotations from a COCO format JSON file and converts them to the YOLO format.\n",
        "    It also generates a `data.yaml` file that describes the dataset.\n",
        "    In YOLO format, each image has a corresponding .txt file containing the bounding box annotations.\n",
        "    Each line in the .txt file follows the format:\n",
        "\n",
        "    class_id center_x center_y width height\n",
        "\n",
        "    Where:\n",
        "    - `class_id` is the ID of the object class (starting from 0).\n",
        "    - `center_x`, `center_y` are the normalized coordinates of the bounding box center.\n",
        "    - `width`, `height` are the normalized dimensions of the bounding box.\n",
        "\n",
        "    The coordinates and dimensions are normalized with respect to the image width and height.\n",
        "\n",
        "    The function processes each annotation in the COCO dataset, converts the bounding box to YOLO format\n",
        "    using the `pybboxes` library, and saves the results in a .txt file named after the corresponding image.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    class_names = [category['name'] for category in coco_data['categories']]\n",
        "\n",
        "    with open(coco_annotation_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    category_id_to_yolo_id = {category['id']: idx for idx, category in enumerate(coco_data['categories'])}\n",
        "\n",
        "    # Process each annotation\n",
        "    for annotation in coco_data['annotations']:\n",
        "        image_id = annotation['image_id']\n",
        "        category_id = annotation['category_id']\n",
        "        bbox = annotation['bbox']\n",
        "\n",
        "        # Get image file name and size\n",
        "        image_info = next(image for image in coco_data['images'] if image['id'] == image_id)\n",
        "        image_filename = image_info['file_name']\n",
        "        image_path = os.path.join(images_dir, image_filename)\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Warning: Label file not found for image: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        with Image.open(image_path) as img:\n",
        "            image_size = img.size  # (width, height)\n",
        "\n",
        "        yolo_bbox = pbx.convert_bbox(bbox, from_type=\"coco\", to_type=\"yolo\", image_size=image_size)\n",
        "\n",
        "        yolo_class_id = category_id_to_yolo_id[category_id]\n",
        "\n",
        "        yolo_annotation_line = f\"{yolo_class_id} {' '.join(map(str, yolo_bbox))}\\n\"\n",
        "\n",
        "        yolo_annotation_file = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}.txt\")\n",
        "\n",
        "        with open(yolo_annotation_file, 'a') as yolo_file:\n",
        "            yolo_file.write(yolo_annotation_line)\n",
        "\n",
        "    yaml_content = {\n",
        "        'nc': len(class_names),                     # Number of classes\n",
        "        'names': class_names                        # List of class names\n",
        "    }\n",
        "\n",
        "    # Determine where to save the YAML file\n",
        "    if yaml_output_path is None:\n",
        "        yaml_output_path = os.path.join(output_dir, 'data.yaml')\n",
        "\n",
        "    # Save the YAML file\n",
        "    with open(yaml_output_path, 'w') as yaml_file:\n",
        "        yaml.dump(yaml_content, yaml_file)\n",
        "\n",
        "    print(f\"YOLO annotations and data.yaml have been saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "l6GaMsU3-RnB",
        "outputId": "3be3fd3e-acc5-44fa-fe9c-049ffc8087aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 0, 2: 1, 3: 2}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-501ff36529e6>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m coco_to_yolo(\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mcoco_annotation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/coco/annotations/filtered_val.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/coco/val2017'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-501ff36529e6>\u001b[0m in \u001b[0;36mcoco_to_yolo\u001b[0;34m(coco_annotation_path, images_dir, output_dir)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Open image to get its dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m  \u001b[0;31m# (width, height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3268\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_open_core\u001b[0;34m(fp, filename, prefix, formats)\u001b[0m\n\u001b[1;32m   3252\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3254\u001b[0;31m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3255\u001b[0m                     \u001b[0m_decompression_bomb_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36mjpeg_factory\u001b[0;34m(fp, filename)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;31m# Factory for making JPEG and MPO instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjpeg_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJpegImageFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mmpheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean folders\n",
        "!rm -r /data/coco/annotations/yolo_format/"
      ],
      "metadata": {
        "id": "_V8jM5dRMvvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_to_yolo(\n",
        "    coco_annotation_path='/data/coco/annotations/filtered_val.json',\n",
        "    images_dir='/data/coco/val2017',\n",
        "    output_dir='/data/coco/annotations/yolo_format/'\n",
        ")"
      ],
      "metadata": {
        "id": "rkQHzGGrMq0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filtered_dataset, dataset_params, input_params, split_ratios=(0.7, 0.2, 0.1), move_files=False):\n",
        "    \"\"\"\n",
        "    Create a dataset structure for training, validation, and test sets with images and YOLO labels.\n",
        "\n",
        "    Parameters:\n",
        "    - filtered_dataset (dict): Dictionary containing filtered 'images', 'annotations', and 'categories'.\n",
        "    - dataset_params (dict): Dictionary defining the dataset structure and paths.\n",
        "    - input_params (dict): Dictionary defining the input structure with paths to images and labels.\n",
        "    - split_ratios (tuple): Ratios for splitting the dataset into (train, valid, test).\n",
        "    - move_files (bool): Whether to move files instead of copying.\n",
        "\n",
        "    Description:\n",
        "    This function divides images into train, validation, and test sets based on the provided split ratios.\n",
        "    Labels has to be first processed by coco_to_yolo function. It then copies or moves the images\n",
        "    and corresponding YOLOv5 format label files from the input directories to the designated\n",
        "    output folders as per the structure defined in `dataset_params`.\n",
        "    \"\"\"\n",
        "\n",
        "    for dir_path in [dataset_params['train_images_dir'], dataset_params['train_labels_dir'],\n",
        "                     dataset_params['val_images_dir'], dataset_params['val_labels_dir'],\n",
        "                     dataset_params['test_images_dir'], dataset_params['test_labels_dir']]:\n",
        "        full_path = os.path.join(dataset_params['data_dir'], dir_path)\n",
        "        os.makedirs(full_path, exist_ok=True)\n",
        "\n",
        "    images = filtered_dataset['images']\n",
        "    random.shuffle(images)\n",
        "\n",
        "    train_idx = int(len(images) * split_ratios[0])\n",
        "    val_idx = train_idx + int(len(images) * split_ratios[1])\n",
        "\n",
        "    train_images = images[:train_idx]\n",
        "    val_images = images[train_idx:val_idx]\n",
        "    test_images = images[val_idx:]\n",
        "\n",
        "    def process_images(image_set, image_dir, label_dir):\n",
        "        for image_info in image_set:\n",
        "            image_filename = image_info['file_name']\n",
        "            yolo_label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "\n",
        "            image_src_path = os.path.join(input_params['images_dir'], image_filename)\n",
        "            label_src_path = os.path.join(input_params['labels_dir'], yolo_label_filename)\n",
        "\n",
        "            image_dest_path = os.path.join(dataset_params['data_dir'], image_dir, image_filename)\n",
        "            label_dest_path = os.path.join(dataset_params['data_dir'], label_dir, yolo_label_filename)\n",
        "\n",
        "            # Copy or move files\n",
        "            if move_files:\n",
        "                shutil.move(image_src_path, image_dest_path)\n",
        "                shutil.move(label_src_path, label_dest_path)\n",
        "            else:\n",
        "                shutil.copy(image_src_path, image_dest_path)\n",
        "                shutil.copy(label_src_path, label_dest_path)\n",
        "\n",
        "    # Process each set\n",
        "    process_images(train_images, dataset_params['train_images_dir'], dataset_params['train_labels_dir'])\n",
        "    process_images(val_images, dataset_params['val_images_dir'], dataset_params['val_labels_dir'])\n",
        "    process_images(test_images, dataset_params['test_images_dir'], dataset_params['test_labels_dir'])\n",
        "\n",
        "    print(f\"Dataset created in {dataset_params['data_dir']} with train/val/test splits.\")"
      ],
      "metadata": {
        "id": "Xvs0Gn_DQAK6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir': '/content/dataset_train',\n",
        "    'train_images_dir': 'train/images',\n",
        "    'train_labels_dir': 'train/labels',\n",
        "    'val_images_dir': 'valid/images',\n",
        "    'val_labels_dir': 'valid/labels',\n",
        "    'test_images_dir': 'test/images',\n",
        "    'test_labels_dir': 'test/labels',\n",
        "    'classes': ['person', 'cat', 'dog']\n",
        "}\n",
        "\n",
        "input_params = {\n",
        "    'images_dir': '/data/coco/val2017',\n",
        "    'labels_dir': '/data/coco/annotations/yolo_format'\n",
        "}\n",
        "\n",
        "split_ratios = (0.7, 0.2, 0.1)\n",
        "\n",
        "create_dataset(filtered_dataset, dataset_params, input_params, split_ratios=split_ratios, move_files=False)"
      ],
      "metadata": {
        "id": "0EPfSh0oUtg8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "6i4QGqCYW2Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_dataset_creation(input_params, dataset_params, split_ratios):\n",
        "\n",
        "    # List all files in the input directories\n",
        "    input_images = set(os.listdir(input_params['images_dir']))\n",
        "    input_labels = set(os.listdir(input_params['labels_dir']))\n",
        "\n",
        "    # List all files in the output directories\n",
        "    train_images = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['train_images_dir'])))\n",
        "    train_labels = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['train_labels_dir'])))\n",
        "\n",
        "    val_images = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['val_images_dir'])))\n",
        "    val_labels = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['val_labels_dir'])))\n",
        "\n",
        "    test_images = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['test_images_dir'])))\n",
        "    test_labels = set(os.listdir(os.path.join(dataset_params['data_dir'], dataset_params['test_labels_dir'])))\n",
        "\n",
        "    # Check if all images and labels were moved or copied\n",
        "    output_images = train_images | val_images | test_images\n",
        "    output_labels = train_labels | val_labels | test_labels\n",
        "\n",
        "    assert input_images == output_images, f\"Mismatch in images. Missing images: {input_images - output_images}\"\n",
        "    assert input_labels == output_labels, f\"Mismatch in labels. Missing labels: {input_labels - output_labels}\"\n",
        "\n",
        "    # Check proportions\n",
        "    total_images = len(input_images)\n",
        "    total_labels = len(input_labels)\n",
        "\n",
        "    assert len(train_images) == len(train_labels),\n",
        "    assert len(val_images) == len(val_labels),\n",
        "    assert len(test_images) == len(test_labels),\n",
        "\n",
        "    expected_train_size = int(total_images * split_ratios[0])\n",
        "    expected_val_size = int(total_images * split_ratios[1])\n",
        "    expected_test_size = total_images - expected_train_size - expected_val_size\n",
        "\n",
        "    assert len(train_images) == expected_train_size, f\"Training set size is incorrect. Expected {expected_train_size}, got {len(train_images)}\"\n",
        "    assert len(val_images) == expected_val_size, f\"Validation set size is incorrect. Expected {expected_val_size}, got {len(val_images)}\"\n",
        "    assert len(test_images) == expected_test_size, f\"Test set size is incorrect. Expected {expected_test_size}, got {len(test_images)}\"\n",
        "\n",
        "    print(\"All tests passed successfully.\")\n"
      ],
      "metadata": {
        "id": "ERQxRGRKW5VC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_creation(input_params, dataset_params, split_ratios)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nKIe3rAXNgL",
        "outputId": "ac7db49b-6658-4f56-dffa-12f984d253ed"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2945 2061\n",
            "All tests passed successfully.\n"
          ]
        }
      ]
    }
  ]
}