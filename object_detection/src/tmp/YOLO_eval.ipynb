{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOoRGpTvj0o",
        "outputId": "426643fa-a0c5-4abc-e97c-0e3f46b4ad94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optax==0.2.1\n",
            "  Downloading optax-0.2.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax==0.2.1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax==0.2.1) (0.1.86)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.10/dist-packages (from optax==0.2.1) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax==0.2.1) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from optax==0.2.1) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax==0.2.1) (4.12.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax==0.2.1) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax==0.2.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax==0.2.1) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax==0.2.1) (1.13.1)\n",
            "Downloading optax-0.2.1-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.9/209.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optax\n",
            "  Attempting uninstall: optax\n",
            "    Found existing installation: optax 0.2.2\n",
            "    Uninstalling optax-0.2.2:\n",
            "      Successfully uninstalled optax-0.2.2\n",
            "Successfully installed optax-0.2.1\n",
            "Collecting chex==0.1.7\n",
            "  Downloading chex-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (1.4.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (0.1.8)\n",
            "Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (1.26.4)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex==0.1.7) (4.12.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.6->chex==0.1.7) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.6->chex==0.1.7) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.6->chex==0.1.7) (1.13.1)\n",
            "Downloading chex-0.1.7-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chex\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.86\n",
            "    Uninstalling chex-0.1.86:\n",
            "      Successfully uninstalled chex-0.1.86\n",
            "Successfully installed chex-0.1.7\n",
            "Collecting pyarrow==14.0.1\n",
            "  Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==14.0.1) (1.26.4)\n",
            "Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "Successfully installed pyarrow-14.0.1\n",
            "Collecting requests==2.31.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.7.4)\n",
            "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.31.0\n",
            "Requirement already satisfied: pandas==2.1.4 in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.4) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.4) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install optax==0.2.1\n",
        "!pip install chex==0.1.7\n",
        "!pip install pyarrow==14.0.1  # Choose a version compatible with most other dependencies\n",
        "!pip install requests==2.31.0\n",
        "!pip install pandas==2.1.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Jozefov/super-gradients.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aimlRjXmvsk2",
        "outputId": "412108dc-7c02-430b-dd55-592e8f98f877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Jozefov/super-gradients.git\n",
            "  Cloning https://github.com/Jozefov/super-gradients.git to /tmp/pip-req-build-40y1sxm1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Jozefov/super-gradients.git /tmp/pip-req-build-40y1sxm1\n",
            "  Resolved https://github.com/Jozefov/super-gradients.git to commit 60548033d226d39e9247f99b37b2beaf179267c1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (4.66.5)\n",
            "Collecting boto3>=1.17.15 (from super-gradients==3.7.1+master)\n",
            "  Downloading boto3-1.34.156-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (4.23.0)\n",
            "Collecting Deprecated>=1.2.11 (from super-gradients==3.7.1+master)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (3.7.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (2.17.0)\n",
            "Collecting setuptools<67.0.0,>=65.5.1 (from super-gradients==3.7.1+master)\n",
            "  Downloading setuptools-66.1.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (0.18.1+cu121)\n",
            "Collecting torchmetrics==0.8 (from super-gradients==3.7.1+master)\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting hydra-core>=1.2.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting onnxruntime>=1.15.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting onnx==1.15.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting pillow>=10.2.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pip-tools>=6.12.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (7.4.1)\n",
            "Collecting einops==0.3.2 (from super-gradients==3.7.1+master)\n",
            "  Downloading einops-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting treelib==1.6.1 (from super-gradients==3.7.1+master)\n",
            "  Downloading treelib-1.6.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting termcolor==1.1.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (24.1)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (0.44.0)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (2.16.1)\n",
            "Collecting stringcase>=1.2.0 (from super-gradients==3.7.1+master)\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from super-gradients==3.7.1+master)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting json-tricks==3.16.1 (from super-gradients==3.7.1+master)\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting onnxsim<1.0,>=0.4.3 (from super-gradients==3.7.1+master)\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting data-gradients~=0.3.1 (from super-gradients==3.7.1+master)\n",
            "  Downloading data_gradients-0.3.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: albumentations~=1.3 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (1.4.12)\n",
            "Requirement already satisfied: fonttools>=4.43.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (4.53.1)\n",
            "Requirement already satisfied: werkzeug>=2.3.8 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (3.0.3)\n",
            "Requirement already satisfied: imagesize~=1.4.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.7.1+master) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx==1.15.0->super-gradients==3.7.1+master) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.15.0->super-gradients==3.7.1+master) (3.20.3)\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics==0.8->super-gradients==3.7.1+master)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from treelib==1.6.1->super-gradients==3.7.1+master) (1.0.0)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (0.23.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (4.12.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (2.8.2)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (0.0.13)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations~=1.3->super-gradients==3.7.1+master) (4.10.0.84)\n",
            "Collecting botocore<1.35.0,>=1.34.156 (from boto3>=1.17.15->super-gradients==3.7.1+master)\n",
            "  Downloading botocore-1.34.156-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.17.15->super-gradients==3.7.1+master)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.17.15->super-gradients==3.7.1+master)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting omegaconf>=2.2.3 (from data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients~=0.3.1->super-gradients==3.7.1+master) (4.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from data-gradients~=0.3.1->super-gradients==3.7.1+master) (4.10.0.84)\n",
            "Collecting coverage~=5.3.1 (from data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading coverage-5.3.1.tar.gz (684 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.5/684.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients~=0.3.1->super-gradients==3.7.1+master) (0.13.1)\n",
            "Collecting xhtml2pdf==0.2.11 (from data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading xhtml2pdf-0.2.11.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients~=0.3.1->super-gradients==3.7.1+master) (3.1.4)\n",
            "Collecting imagededup (from data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting arabic-reshaper>=3.0.0 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.1)\n",
            "Collecting pyHanko>=0.12.1 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading pyHanko-0.25.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading pyhanko_certvalidator-0.26.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pypdf>=3.1.0 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting python-bidi>=0.4.2 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting reportlab<4,>=3.5.53 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading reportlab-3.6.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting svglib>=1.2.1 (from xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading svglib-1.5.1.tar.gz (913 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated>=1.2.11->super-gradients==3.7.1+master) (1.16.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.2.0->super-gradients==3.7.1+master)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.7.1+master) (24.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.7.1+master) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.7.1+master) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.7.1+master) (0.19.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.7.1+master) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.7.1+master) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.7.1+master) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.7.1+master) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.7.1+master) (2.8.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.0->super-gradients==3.7.1+master)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->super-gradients==3.7.1+master) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->super-gradients==3.7.1+master) (1.13.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim<1.0,>=0.4.3->super-gradients==3.7.1+master) (13.7.1)\n",
            "Requirement already satisfied: build>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.7.1+master) (1.2.1)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.7.1+master) (8.1.7)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.7.1+master) (24.1.2)\n",
            "Requirement already satisfied: pyproject-hooks in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.7.1+master) (1.1.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.7.1+master) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.7.1+master) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.7.1+master) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.7.1+master) (3.6)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.7.1+master) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.7.1+master) (0.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.7.1+master) (3.15.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.7.1+master) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.7.1+master) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.7.1+master) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->super-gradients==3.7.1+master)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.3.8->super-gradients==3.7.1+master) (2.1.5)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.156->boto3>=1.17.15->super-gradients==3.7.1+master) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations~=1.3->super-gradients==3.7.1+master) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations~=1.3->super-gradients==3.7.1+master) (2.20.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations~=1.3->super-gradients==3.7.1+master) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations~=1.3->super-gradients==3.7.1+master) (2024.7.24)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations~=1.3->super-gradients==3.7.1+master) (0.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.0->super-gradients==3.7.1+master)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.3.2)\n",
            "Collecting PyWavelets (from imagededup->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim<1.0,>=0.4.3->super-gradients==3.7.1+master) (3.0.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.0->super-gradients==3.7.1+master) (1.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (0.5.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim<1.0,>=0.4.3->super-gradients==3.7.1+master) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2024.1)\n",
            "Requirement already satisfied: asn1crypto>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.5.1)\n",
            "Collecting qrcode>=7.3.1 (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading qrcode-7.4.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (5.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2.31.0)\n",
            "Requirement already satisfied: cryptography>=42.0.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (42.0.8)\n",
            "Collecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading uritools-4.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (4.9.4)\n",
            "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.3.0)\n",
            "Collecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients~=0.3.1->super-gradients==3.7.1+master) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=42.0.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (1.16.0)\n",
            "Collecting pypng (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master)\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2024.7.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=42.0.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients==3.7.1+master) (2.22)\n",
            "Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Downloading boto3-1.34.156-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading data_gradients-0.3.2-py3-none-any.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.5/459.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-66.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.156-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyHanko-0.25.1-py3-none-any.whl (446 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.0/447.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyhanko_certvalidator-0.26.3-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading reportlab-3.6.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uritools-4.0.3-py3-none-any.whl (10 kB)\n",
            "Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: super-gradients, termcolor, treelib, xhtml2pdf, antlr4-python3-runtime, stringcase, coverage, svglib\n",
            "  Building wheel for super-gradients (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for super-gradients: filename=super_gradients-3.7.1+master-py3-none-any.whl size=12124896 sha256=94f64bcebf336c03ed971519cd98e712293812ece383ecb6287154309d0bb7ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0czdr1nc/wheels/c9/0b/cc/a91a5de0fdc4ea31e75a4f546384de2cb0857053de15ed6b05\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=bc02da107a931411614431f72743c9c1842c7de0dec7ca0a75b62df6bd1493bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-py3-none-any.whl size=18369 sha256=0f5e1ae452d4806fa1cf072fbc495e715f2871df3e6ee73c6f1554c761f4b824\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/72/8b/76569b82bf280a03c4e294c3b29ee2398217186369c427ed4b\n",
            "  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.11-py3-none-any.whl size=262644 sha256=32beb232def3f1267b827e6daad0bfe9303a05157ddf340288fb035a40bf71eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/77/fb/e473c11c4e30a7680bf5b1b7f1d07ef04932184a2f39118e8d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=70fe38d22186192acd5f7c7d6c4ae89acf8b932b78c96ef33ed7427fd866ca05\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3569 sha256=90d0d0de41f41b19e768ec7a2a1ec122176ab9d1ea30c8900df320b63676d362\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n",
            "  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coverage: filename=coverage-5.3.1-cp310-cp310-linux_x86_64.whl size=235258 sha256=a49e1f8656205cde930310d2430717b0d818f986744f7b465ed64c6cf279834b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/70/10/313be697f460d6024cfa94b7f0e22ffc1c53aab718fb4f42af\n",
            "  Building wheel for svglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30906 sha256=65ff3fa4348a4d852ce3c8fa926effbe1a0fac3b795981896d506f6201fe74b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n",
            "Successfully built super-gradients termcolor treelib xhtml2pdf antlr4-python3-runtime stringcase coverage svglib\n",
            "Installing collected packages: termcolor, stringcase, python-bidi, pypng, json-tricks, einops, arabic-reshaper, antlr4-python3-runtime, uritools, treelib, setuptools, rapidfuzz, qrcode, PyWavelets, pypdf, pyDeprecate, pillow, oscrypto, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, humanfriendly, Deprecated, coverage, reportlab, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, cssselect2, coloredlogs, botocore, svglib, s3transfer, pyhanko-certvalidator, onnxsim, onnxruntime, nvidia-cusolver-cu12, pyHanko, boto3, xhtml2pdf, torchmetrics, imagededup, data-gradients, super-gradients\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.4.0\n",
            "    Uninstalling termcolor-2.4.0:\n",
            "      Successfully uninstalled termcolor-2.4.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 PyWavelets-1.6.0 antlr4-python3-runtime-4.9.3 arabic-reshaper-3.0.0 boto3-1.34.156 botocore-1.34.156 coloredlogs-15.0.1 coverage-5.3.1 cssselect2-0.7.0 data-gradients-0.3.2 einops-0.3.2 humanfriendly-10.0 hydra-core-1.3.2 imagededup-0.3.2 jmespath-1.0.1 json-tricks-3.16.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.15.0 onnxruntime-1.18.1 onnxsim-0.4.36 oscrypto-1.3.0 pillow-10.4.0 pyDeprecate-0.3.2 pyHanko-0.25.1 pyhanko-certvalidator-0.26.3 pypdf-4.3.1 pypng-0.20220715.0 python-bidi-0.6.0 qrcode-7.4.2 rapidfuzz-3.9.6 reportlab-3.6.13 s3transfer-0.10.2 setuptools-66.1.1 stringcase-1.2.0 super-gradients-3.7.1+master svglib-1.5.1 termcolor-1.1.0 torchmetrics-0.8.0 treelib-1.6.1 uritools-4.0.3 xhtml2pdf-0.2.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools"
                ]
              },
              "id": "f4f75cee6fbc49f6976bbe47417def41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26\n",
        "!pip install matplotlib==3.5\n",
        "!pip install opencv-python\n",
        "!pip install pybboxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGoXC0DSvux7",
        "outputId": "cfacb59c-b3d0-4908-ae8c-b82c8aa137f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Cartucho/mAP"
      ],
      "metadata": {
        "id": "R5zSqnhbv81n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import super_gradients\n",
        "import torch\n",
        "import random\n",
        "import pybboxes as pbx\n",
        "\n",
        "from super_gradients.common.object_names import Models\n",
        "from super_gradients.training import models\n",
        "from super_gradients.training import dataloaders\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ],
      "metadata": {
        "id": "zfPuk9NLwEGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download COCO dataset**"
      ],
      "metadata": {
        "id": "bcUZBq_OweLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /data/coco/\n",
        "\n",
        "# Download the annotation ZIP and extract it, then remove the ZIP file\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q annotations_trainval2017.zip -d /data/coco/\n",
        "!rm annotations_trainval2017.zip\n",
        "\n",
        "# Download the train2017 ZIP, extract it, and remove the ZIP file\n",
        "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
        "# !unzip -q train2017.zip -d /data/coco/\n",
        "# !rm train2017.zip\n",
        "\n",
        "# Download the val2017 ZIP, extract it, and remove the ZIP file\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip -q val2017.\n",
        "!rm val2017.zip"
      ],
      "metadata": {
        "id": "ClE3z2FAwEJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model, optionally with pretrained weights\n",
        "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")"
      ],
      "metadata": {
        "id": "WV8ycDIWwELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your COCO validation images\n",
        "coco_val_directory = '/data/coco/val2017'\n",
        "\n",
        "# List all jpg images in the validation directory\n",
        "# Also important as on this will be based your sortings of prediction\n",
        "image_paths = [os.path.join(coco_val_directory, img) for img in os.listdir(coco_val_directory) if img.endswith('.jpg')]\n"
      ],
      "metadata": {
        "id": "MKgKjB4hwEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and return only predictions witch confidence above 0.5\n",
        "model_predictions = model.to(device).predict(image_paths, conf=0.50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "KeT_3Y77w_Sd",
        "outputId": "85ce4c9f-8d45-477e-ac9f-e1ed439a0233"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-120f476cd54b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_predictions.save(output_folder='/data/prediction/val/images')"
      ],
      "metadata": {
        "id": "pK7vR3HZxAV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predictions[0].show()"
      ],
      "metadata": {
        "id": "TYWM6ihtxV1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding out how prediction are stored, renamed and sorted"
      ],
      "metadata": {
        "id": "994fy356xbuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the predicted images directory\n",
        "predicted_val_directory = '/data/prediction/val/images'\n",
        "\n",
        "# List all jpg images in the predicted images directory and sort them\n",
        "predicted_image_paths = sorted(\n",
        "    [os.path.join(predicted_val_directory, img) for img in os.listdir(predicted_val_directory) if img.endswith('.jpg')],\n",
        "    key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[1])\n",
        ")\n",
        "\n",
        "# Print out sorted file names to confirm the order\n",
        "print(\"Predicted images (sorted, first 5):\", [os.path.basename(path) for path in predicted_image_paths[:5]])"
      ],
      "metadata": {
        "id": "FkjGdj24xV4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print images in predicted and original folder\n",
        "indices = [0, 1, 2, 3, 4]\n",
        "\n",
        "fig, axes = plt.subplots(len(indices), 2, figsize=(10, 5 * len(indices)))\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    original_image = Image.open(image_paths[idx])\n",
        "    predicted_image = Image.open(predicted_image_paths[idx])\n",
        "\n",
        "    # Display original image\n",
        "    axes[i, 0].imshow(original_image)\n",
        "    axes[i, 0].set_title(f'Original - {os.path.basename(image_paths[idx])}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display predicted image\n",
        "    axes[i, 1].imshow(predicted_image)\n",
        "    axes[i, 1].set_title(f'Predicted - {os.path.basename(predicted_image_paths[idx])}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pR7AgH5zxV6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Renaming predicted images to original format"
      ],
      "metadata": {
        "id": "JQdhauA6yEG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the number of files matches\n",
        "if len(image_paths) != len(predicted_image_paths):\n",
        "    print(\"The number of original and predicted images does not match. Aborting renaming.\")\n",
        "else:\n",
        "    # Rename files\n",
        "    for orig_path, pred_path in zip(image_paths, predicted_image_paths):\n",
        "        new_name = os.path.basename(orig_path)\n",
        "        new_pred_path = os.path.join(predicted_val_directory, new_name)\n",
        "        os.rename(pred_path, new_pred_path)\n",
        "\n",
        "    print(\"All predicted images have been successfully renamed.\")"
      ],
      "metadata": {
        "id": "U1RNyCMIxV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again compare\n",
        "coco_val_directory = '/data/coco/val2017'\n",
        "predicted_val_directory = '/data/prediction/val/images'\n",
        "\n",
        "original_image_paths = sorted(\n",
        "    [os.path.join(coco_val_directory, img) for img in os.listdir(coco_val_directory) if img.endswith('.jpg')]\n",
        ")\n",
        "\n",
        "predicted_image_paths = sorted(\n",
        "    [os.path.join(predicted_val_directory, img) for img in os.listdir(predicted_val_directory) if img.endswith('.jpg')]\n",
        ")\n",
        "\n",
        "indices = random.sample(range(len(original_image_paths)), 5)\n",
        "\n",
        "fig, axes = plt.subplots(5, 2, figsize=(10, 25))\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "\n",
        "    original_image = Image.open(original_image_paths[idx])\n",
        "    predicted_image = Image.open(predicted_image_paths[idx])\n",
        "\n",
        "    # Display original image\n",
        "    axes[i, 0].imshow(original_image)\n",
        "    axes[i, 0].set_title(f'Original - {os.path.basename(original_image_paths[idx])}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Display predicted image\n",
        "    axes[i, 1].imshow(predicted_image)\n",
        "    axes[i, 1].set_title(f'Predicted - {os.path.basename(predicted_image_paths[idx])}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zOm-wpzYxV-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate with mAP"
      ],
      "metadata": {
        "id": "itBlGIStyjpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coco_to_map_with_conversion(coco_annotation_path, image_paths, model_predictions, output_dir,\n",
        "                                input_format_truth='coco', input_format_pred='voc'):\n",
        "\n",
        "    \"\"\"\n",
        "    Converts COCO annotations and model predictions to the required format for mAP evaluation (voc format).\n",
        "\n",
        "    Args:\n",
        "        coco_annotation_path (str): Path to the COCO annotations JSON file.\n",
        "        image_paths (list of str): List of image file paths corresponding to the model predictions.\n",
        "        model_predictions (list of dict): List of model prediction dictionaries, one for each image.\n",
        "                                          Each prediction should contain (YOLO-NAS format):\n",
        "                                          - 'prediction': {\n",
        "                                              'confidence': list of float,\n",
        "                                              'labels': list of int,\n",
        "                                              'bboxes_xyxy': list of list of float\n",
        "                                            }\n",
        "                                          - 'class_names': list of str,\n",
        "        output_dir (str): Directory to save the ground-truth and detection-results files, have to be in format:\n",
        "            mAP/input to fits in next analytical function.\n",
        "        input_format_truth (str, optional): Input format of the ground-truth bounding boxes ('coco' by default).\n",
        "        input_format_pred (str, optional): Input format of the prediction bounding boxes ('voc' by default).\n",
        "\n",
        "    Returns:\n",
        "        None, create files for prediction in format for Cartucho/mAP git project\n",
        "    \"\"\"\n",
        "\n",
        "    with open(coco_annotation_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    annotations = coco_data['annotations']\n",
        "    images = {image['id']: image['file_name'] for image in coco_data['images']}\n",
        "    image_sizes = {image['id']: (image['width'], image['height']) for image in coco_data['images']}\n",
        "    categories = {category['id']: category['name'].replace(' ', '_') for category in coco_data['categories']}\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Create directories for ground-truth and detection-results\n",
        "    gt_dir = os.path.join(output_dir, 'ground-truth')\n",
        "    dr_dir = os.path.join(output_dir, 'detection-results')\n",
        "    os.makedirs(gt_dir, exist_ok=True)\n",
        "    os.makedirs(dr_dir, exist_ok=True)\n",
        "\n",
        "    # Process ground-truth annotations\n",
        "    for annotation in annotations:\n",
        "        image_id = annotation['image_id']\n",
        "        if image_id not in image_sizes:\n",
        "            print(f\"Error. Image not found with id: {image_id}\")\n",
        "            continue\n",
        "\n",
        "        image_info = next((img for img in coco_data['images'] if img['id'] == image_id), None)\n",
        "        if not image_info:\n",
        "            print(f\"Error. Image not found with id: {image_id}\")\n",
        "            continue\n",
        "\n",
        "        image_file = images[image_id]\n",
        "        image_size = image_sizes[image_id]\n",
        "\n",
        "        category_id = annotation['category_id']\n",
        "        category_name = categories[category_id]\n",
        "        bbox = annotation['bbox']\n",
        "\n",
        "\n",
        "        # Convert back to COCO format for evaluation\n",
        "        if input_format_truth != 'coco':\n",
        "            converted_bbox = pbx.convert_bbox(bbox, from_type=input_format_truth, \\\n",
        "                                                   to_type='coco', image_size=image_size)\n",
        "        else:\n",
        "            converted_bbox = bbox\n",
        "\n",
        "        output_file = os.path.join(gt_dir, image_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        xmin, ymin, width, height = converted_bbox\n",
        "        xmax = xmin + width\n",
        "        ymax = ymin + height\n",
        "\n",
        "        with open(output_file, 'a') as f:\n",
        "            f.write(f\"{category_name} {xmin} {ymin} {xmax} {ymax}\\n\")\n",
        "\n",
        "    # Process model predictions\n",
        "    for image_path, predictions in zip(image_paths, model_predictions):\n",
        "        image_file = os.path.basename(image_path)\n",
        "        image_id = int(os.path.splitext(image_file)[0])\n",
        "\n",
        "        if image_id not in images:\n",
        "            print(f\"Error. Image not found with name: {image_file}\")\n",
        "            continue\n",
        "\n",
        "        image_size = image_sizes[image_id]\n",
        "\n",
        "        output_file = os.path.join(dr_dir, image_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            for j, score in enumerate(predictions.prediction.confidence):\n",
        "                category_name = predictions.class_names[predictions.prediction.labels[j]].replace(' ', '_')\n",
        "                bbox = predictions.prediction.bboxes_xyxy[j]\n",
        "\n",
        "                converted_back_bbox = pbx.convert_bbox(bbox, from_type=input_format_pred, to_type=\"coco\", image_size=image_size)\n",
        "\n",
        "                xmin, ymin, width, height = converted_back_bbox\n",
        "                xmax = xmin + width\n",
        "                ymax = ymin + height\n",
        "\n",
        "                f.write(f\"{category_name} {score} {xmin} {ymin} {xmax} {ymax}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SDeMYgnWyjFs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean folders\n",
        "!rm -r /content/mAP/input/ground-truth/\n",
        "!rm -r /content/mAP/input/detection-results/\n",
        "!rm -r /content/mAP/input/images-optional"
      ],
      "metadata": {
        "id": "0USmXrBw6J8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_to_map_with_conversion('/data/coco/annotations/instances_val2017.json', image_paths, model_predictions, 'mAP/input', input_format_truth='coco', input_format_pred='voc')"
      ],
      "metadata": {
        "id": "vPT2P723yjJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compares files in ground-truth and detection-results directories and optionally removes extra or missing files\n",
        "def compare_ground_truth_and_detection_results(gt_dir, dr_dir, remove_extra=False, remove_missing=False):\n",
        "    gt_files = set(os.listdir(gt_dir))\n",
        "    dr_files = set(os.listdir(dr_dir))\n",
        "\n",
        "    missing_files = gt_files - dr_files\n",
        "    extra_files = dr_files - gt_files\n",
        "\n",
        "    if not missing_files and not extra_files:\n",
        "        print(\"All ground-truth files have corresponding detection-results files.\")\n",
        "    else:\n",
        "        if missing_files:\n",
        "            print(\"Missing detection-results files for the following ground-truth files:\")\n",
        "            for file in missing_files:\n",
        "                print(file)\n",
        "                if remove_missing:\n",
        "                    os.remove(os.path.join(gt_dir, file))\n",
        "                    print(f\"Removed: {file}\")\n",
        "\n",
        "        if extra_files:\n",
        "            print(\"Extra detection-results files that do not have corresponding ground-truth files:\")\n",
        "            print(len(extra_files))\n",
        "            for file in extra_files:\n",
        "                print(file)\n",
        "                if remove_extra:\n",
        "                    os.remove(os.path.join(dr_dir, file))\n",
        "                    print(f\"Removed: {file}\")\n"
      ],
      "metadata": {
        "id": "RmnEjNTAyjHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt_dir = '/content/mAP/input/ground-truth/'\n",
        "dr_dir = '/content/mAP/input/detection-results/'\n",
        "\n",
        "# romove files fow which prediction or annotation is missing, found out coco is missing annotation for 48 images\n",
        "compare_ground_truth_and_detection_results(gt_dir, dr_dir, remove_extra=True, remove_missing=True)"
      ],
      "metadata": {
        "id": "IQBHlA_WyjMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "%cd /content/\n",
        "%cd mAP\n",
        "!python main.py -na\n",
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYlcTyGbyjPE",
        "outputId": "4c7069e6-a367-427e-9b01-9096a100705e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "[Errno 2] No such file or directory: 'mAP'\n",
            "/content\n",
            "python3: can't open file '/content/main.py': [Errno 2] No such file or directory\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3BzvNke0yjRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BVQXe_lyjT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhppeN-tyiUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}